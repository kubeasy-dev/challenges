# Kubeasy ‚Äì Challenge Review Workflow

## Objectif

Ce workflow permet d‚Äô√©valuer la qualit√© p√©dagogique, la coh√©rence et la robustesse des challenges Kubeasy, en simulant le comportement d‚Äôun utilisateur r√©el d√©couvrant un challenge Kubernetes.

Il vise √† identifier :
- les challenges contournables (bypass)
- les incoh√©rences entre description et validation
- les validations trop strictes ou trop laxistes
- les probl√®mes d‚Äôexp√©rience utilisateur (UX, feedback, erreurs)

## R√¥le de l‚Äôagent

Tu es un ing√©nieur Kubernetes confirm√©.Tu :
- d√©couvres chaque challenge sans conna√Ætre la solution
- ne supposes jamais l‚Äôintention de l‚Äôauteur
- juges uniquement ce qui est observable, document√© et valid√©

## Parcours des challenges

Parcours tous les dossiers du r√©pertoire challenges/, √† l‚Äôexception des dossiers `.github` et `.claude`. Un dossier correspond √† un challenge unique.

### 1.Analyse statique du challenge
Ouvre le fichier challenge.yaml et analyse explicitement les cl√©s suivantes :
- `slug`: Identifiant unique du challenge (doit correspondre au nom du dossier)
- `theme`: Th√©matique principale du challenge (ex: rbac, storage, networking, workloads)
- `difficulty`: Niveau annonc√© (easy, medium, hard)
- `estimated_time`: Temps estim√© en minutes pour un utilisateur standard
- `initial_situation`: Description du contexte initial du challenge (situation r√©aliste, probl√®me rencontr√©)
- `validations`: Tableau d√©crivant ce qui est r√©ellement valid√© par kubeasy challenge submit

Objectif de cette √©tape : Comprendre ce que le challenge promet et ce qui sera r√©ellement test√©, sans chercher la solution.

### 2. D√©marrage du challenge
D√©marre le challenge avec : `kubeasy challenge start <challenge_slug>` (<challenge_slug> = nom exact du dossier)
Si le message appara√Æt : "WARNING Challenge already started", alors :
- `kubeasy challenge reset <challenge_slug>`
- `kubeasy challenge start <challenge_slug>`

Interdictions strictes:
- `kubeasy setup`
- `kubeasy login`
- toute modification de configuration globale

### 3. Observation de l‚Äô√©tat initial (runtime)
Une fois le challenge d√©marr√©, identifie toutes les ressources Kubernetes du namespace du challenge
Analyse :
- types de ressources (Pod, Deployment, Job, Service, ConfigMap, Secret, RBAC‚Ä¶)
- statuts (Running, Pending, CrashLoopBackOff, etc.)
- logs applicatifs si pertinents
- √©v√©nements Kubernetes (kubectl get events)

Objectif : comprendre la situation r√©elle √† laquelle l‚Äôutilisateur est confront√©.

### 4. Tentative de r√©solution
Tente de r√©soudre le challenge librement. Tu peux :
- utiliser kubectl
- inspecter les manifests
- modifier les ressources existantes

Lorsque tu estimes le challenge r√©solu , lance `kubeasy challenge submit <challenge_slug>`

Trace pr√©cis√©ment :
- les commandes ex√©cut√©es
- les ressources modifi√©es
- les raisonnements cl√©s

### 5. Gestion des √©checs & validation
Si le challenge n‚Äôest pas valid√© : retourne √† l‚Äô√©tape 4 et change d‚Äôapproche

**Limite maximale : 5 tentatives**Si apr√®s 5 essais la validation √©choue, consid√®re qu‚Äôil existe :
- soit une validation incorrecte
- soit un manque de feedback utilisateur

Passe alors √† l‚Äô√©tape 10.

### 6. Analyse de l‚Äôalignement validation ‚Üî solution
Analyse si la solution que tu as mise en place est conceptuellement correcte mais rejet√©e par la validation

Si oui :
- consid√®re le challenge comme non align√©
- note-le comme non coh√©rent

Ce check vise √† d√©tecter les validations trop rigides ou mal con√ßues.

### 7. D√©tection de bypass
Analyse tes actions :
- As-tu contourn√© l‚Äôintention p√©dagogique ?
- As-tu utilis√© une action triviale ou hors-scope ?
- suppression brute (kubectl delete pod --all)
- modification globale non enseignante
- action non document√©e mais valid√©e

Si oui, marque bypassed = true et passe directement √† l‚Äô√©tape 10

### 8. Analyse UX & r√©silience utilisateur
√âvalue si un utilisateur raisonnable peut :
- se retrouver bloqu√© sans comprendre pourquoi
- manquer de feedback clair (logs, √©v√©nements, erreurs)
- r√©ussir par hasard sans comprendre

üëâ Ce point impacte directement la qualit√© p√©dagogique.

### 9. Coh√©rence globale
√Ä partir de ton exp√©rience r√©elle :
- description ‚Üî r√©alit√©
- th√®me ‚Üî actions n√©cessaires
- difficult√© ‚Üî effort r√©el
- temps estim√© ‚Üî temps r√©el

Classe chaque √©l√©ment comme :
- coh√©rent
- sous-estim√©
- sur√©valu√©

### 10. Restitution des r√©sultats
√âcris un objet JSON par challenge dans `/tmp/challenge-tests-results.json`

Format attendu :
{
  "name": "<challenge_slug>",
  "passed": true,
  "bypassed": false,
  "too_easy": false,
  "coherent": true,
  "score": 17
}

#### Grille de scoring (/20)

|Crit√®re|Bar√™me (nombre de point maximal)|
|---|---|
|Clart√© du initial_situation | 4
|Qualit√© p√©dagogique | 4
|Alignement validations ‚Üî solution | 4
|Robustesse / anti-bypass | 4
|UX, difficult√© & temps estim√© | 4


Lecture du score :
- 18‚Äì20 : excellent
- 14‚Äì17 : bon
- 10‚Äì13 : moyen
